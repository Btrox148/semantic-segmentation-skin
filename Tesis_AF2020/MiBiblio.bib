@online{cancer_org,
  author = {The American Cancer Society medical and editorial content team},
  title   = {What Are Basal and Squamous Cell Skin Cancers?},
  year = {2019},
  url = {https://www.cancer.org/cancer/basal-and-squamous-cell-skin-cancer/about/what-is-basal-and-squamous-cell.html},
  urldate = {18-08-2020}
}

@online{cancer_img_1,
  author = {Dr. P. Marazzi},
  title   = {Science Photo Library},
  year = {2012},
  url = {https://ichef.bbci.co.uk/news/660/media/images/77303000/jpg/_77303278_skin_cancer-spl-1.jpg},
  urldate = {18-08-2020}
}

@online{skin_2,
  author = {TORTORA GJ. AND GRABOWSKI SR.},
  title   = {PRINCIPLES OF ANATOMY AND PHYSIOLOGY},
  year = {1993},
  url = {https://www.clinimed.co.uk/wound-care/wound-essentials/structure-and-function-of-the-skin#:~:text=The%20skin%20consists%20of%20two,the%20functions%20of%20the%20skin.},
  urldate = {18-08-2020}
}

@article{wu2019fastfcn,
  title   = {FastFCN: Rethinking dilated convolution in the backbone for semantic segmentation},
  author  = {Wu, Huikai and Zhang, Junge and Huang, Kaiqi and Liang, Kongming and Yu, Yizhou},
  journal = {arXiv preprint arXiv: 1903.11816[cs.CV]},
  year    = {2019},
}

@article{skin_1,
  title   = {Novel approaches for managing aged skin and nonmelanoma skin cancer},
  author  = {K. Todorova and Anna Mandinova},
  journal = {Adv. Drug Deliv. Rev., https://doi.org/10.1016/j.addr.2020.06.004},
  year    = {2020},
}

@article{skin_aging,
  author          = {Laure Rittie and Gary J. Fisher},
  title           = {Natural and Sun-Induced Aging of Human Skin},
  journal         = {Cold Spring Harb Perspect Med, doi: 10.1101/cshperspect.a015370},
  year            = {2015}
}

@misc{Yakubovskiy:2019,
  Author = {Pavel Yakubovskiy},
  Title = {Segmentation Models Pytorch},
  Year = {2020},
  Publisher = {GitHub},
  Journal = {GitHub repository},
  Howpublished = {\url{https://github.com/qubvel/segmentation_models.pytorch}}
}

@article{DBLP:journals/corr/abs-1902-03368,
  author    = {Noel C. F. Codella and
               Veronica Rotemberg and
               Philipp Tschandl and
               M. Emre Celebi and
               Stephen W. Dusza and
               David Gutman and
               Brian Helba and
               Aadi Kalloo and
               Konstantinos Liopyris and
               Michael A. Marchetti and
               Harald Kittler and
               Allan Halpern},
  title     = {Skin Lesion Analysis Toward Melanoma Detection 2018: {A} Challenge
               Hosted by the International Skin Imaging Collaboration {(ISIC)}},
  journal   = {CoRR},
  volume    = {abs/1902.03368},
  year      = {2019},
  url       = {http://arxiv.org/abs/1902.03368},
  archivePrefix = {arXiv},
  eprint    = {1902.03368[cs.CV]},
  timestamp = {Tue, 21 May 2019 18:03:39 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1902-03368.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{beijing2020Suggested,
  title = {Suggested Notation for Machine Learning},
  author = {Beijing Academy of Artificial Intelligence},
  howpublished = {\url{https://github.com/Mayuyu/suggested-notation-for-machine-learning}},
  year=2020
}

@article{DBLP:journals/corr/RonnebergerFB15,
  author    = {Olaf Ronneberger and
               Philipp Fischer and
               Thomas Brox},
  title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  journal   = {CoRR},
  volume    = {abs/1505.04597},
  year      = {2015},
  url       = {http://arxiv.org/abs/1505.04597},
  archivePrefix = {arXiv},
  eprint    = {1505.04597 [cs.CV]},
  timestamp = {Mon, 13 Aug 2018 16:46:52 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/RonnebergerFB15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/BadrinarayananK15,
  author    = {Vijay Badrinarayanan and
               Alex Kendall and
               Roberto Cipolla},
  title     = {SegNet: {A} Deep Convolutional Encoder-Decoder Architecture for Image
               Segmentation},
  journal   = {CoRR},
  volume    = {abs/1511.00561},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.00561},
  archivePrefix = {arXiv},
  eprint    = {1511.00561[cs.CV]},
  timestamp = {Mon, 13 Aug 2018 16:46:06 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/BadrinarayananK15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{KRONER2020261,
title = "Contextual encoder–decoder network for visual saliency prediction",
journal = "Neural Networks",
volume = "129",
pages = "261 - 270",
year = "2020",
issn = "0893-6080",
doi = "https://doi.org/10.1016/j.neunet.2020.05.004",
url = "http://www.sciencedirect.com/science/article/pii/S0893608020301660",
author = "Alexander Kroner and Mario Senden and Kurt Driessens and Rainer Goebel",
keywords = "Saliency prediction, Human fixations, Convolutional neural networks, Computer vision, Deep learning",
abstract = "Predicting salient regions in natural images requires the detection of objects that are present in a scene. To develop robust representations for this challenging task, high-level visual features at multiple spatial scales must be extracted and augmented with contextual information. However, existing models aimed at explaining human fixation maps do not incorporate such a mechanism explicitly. Here we propose an approach based on a convolutional neural network pre-trained on a large-scale image classification task. The architecture forms an encoder–decoder structure and includes a module with multiple convolutional layers at different dilation rates to capture multi-scale features in parallel. Moreover, we combine the resulting representations with global scene information for accurately predicting visual saliency. Our model achieves competitive and consistent results across multiple evaluation metrics on two public saliency benchmarks and we demonstrate the effectiveness of the suggested approach on five datasets and selected examples. Compared to state of the art approaches, the network is based on a lightweight image classification backbone and hence presents a suitable choice for applications with limited computational resources, such as (virtual) robotic systems, to estimate human fixations across complex natural scenes. Our TensorFlow implementation is openly available at https://github.com/alexanderkroner/saliency."
}

@article{DBLP:journals/corr/ChenPK0Y16,
  author    = {Liang{-}Chieh Chen and
               George Papandreou and
               Iasonas Kokkinos and
               Kevin Murphy and
               Alan L. Yuille},
  title     = {DeepLab: Semantic Image Segmentation with Deep Convolutional Nets,
               Atrous Convolution, and Fully Connected CRFs},
  journal   = {CoRR},
  volume    = {abs/1606.00915},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.00915},
  archivePrefix = {arXiv},
  eprint    = {1606.00915[cs.CV]},
  timestamp = {Mon, 13 Aug 2018 16:46:13 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ChenPK0Y16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/ShelhamerLD16,
  author    = {Evan Shelhamer and
               Jonathan Long and
               Trevor Darrell},
  title     = {Fully Convolutional Networks for Semantic Segmentation},
  journal   = {CoRR},
  volume    = {abs/1605.06211[cs.CV]},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.06211},
  archivePrefix = {arXiv},
  eprint    = {1605.06211[cs.CV]},
  timestamp = {Mon, 13 Aug 2018 16:49:10 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ShelhamerLD16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/TeichmannWZCU16,
  author    = {Marvin Teichmann and
               Michael Weber and
               J. Marius Z{\"{o}}llner and
               Roberto Cipolla and
               Raquel Urtasun},
  title     = {MultiNet: Real-time Joint Semantic Reasoning for Autonomous Driving},
  journal   = {CoRR},
  volume    = {abs/1612.07695},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.07695},
  archivePrefix = {arXiv},
  eprint    = {1612.07695[cs.CV]},
  timestamp = {Mon, 13 Aug 2018 16:48:42 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/TeichmannWZCU16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{KADAMPUR2020100282,
title = "Skin cancer detection: Applying a deep learning based model driven architecture in the cloud for classifying dermal cell images",
journal = "Informatics in Medicine Unlocked",
volume = "18",
pages = "100282",
year = "2020",
issn = "2352-9148",
doi = "https://doi.org/10.1016/j.imu.2019.100282",
url = "http://www.sciencedirect.com/science/article/pii/S2352914819302047",
author = "Mohammad Ali Kadampur and Sulaiman {Al Riyaee}",
keywords = "Deep learning, AI, Model driven architecture, Deep cognition studio, CNN, Cancer, Image classification",
abstract = "Background
Skin cancer is a common form of cancer, and early detection increases the survival rate.
Objective
To build deep learning models to classify dermal cell images and detect skin cancer.
Methods
A model-driven architecture in the cloud, that uses deep learning algorithms in its core implementations, is used to construct models that assist in predicting skin cancer with improved accuracy. The study illustrates the method of building models and applying them to classify dermal cell images.
Results
The deep learning models built here are tested on standard datasets, and the metric area under the curve of 99.77% was observed.
Conclusions
A practitioner can use the model-driven architecture and quickly build the deep learning models to predict skin cancer."
}

@article{zhou2019emerging,
  title={Emerging role of machine learning in light-matter interaction},
  author={Zhou, Jiajia and Huang, Bolong and Yan, Zheng and B{\"u}nzli, Jean-Claude G},
  journal={Light: Science \& Applications},
  volume={8},
  number={1},
  pages={1--7},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{DBLP:journals/corr/LucCCV16,
  author    = {Pauline Luc and
               Camille Couprie and
               Soumith Chintala and
               Jakob Verbeek},
  title     = {Semantic Segmentation using Adversarial Networks},
  journal   = {CoRR},
  volume    = {abs/1611.08408},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.08408},
  archivePrefix = {arXiv},
  eprint    = {1611.08408},
  timestamp = {Mon, 13 Aug 2018 16:49:14 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LucCCV16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{JAIN2015735,
title = "Computer Aided Melanoma Skin Cancer Detection Using Image Processing",
journal = "Procedia Computer Science",
volume = "48",
pages = "735 - 740",
year = "2015",
note = "International Conference on Computer, Communication and Convergence (ICCC 2015)",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2015.04.209",
url = "http://www.sciencedirect.com/science/article/pii/S1877050915007188",
author = "Shivangi Jain and Vandana jagtap and Nitin Pise",
keywords = "Melona, Skin Cance, Image Segmentation, Preprocessing, EdgeDetection, Color Threshloding, Blob detection, Binary Masks",
abstract = "In recent days, skin cancer is seen as one of the most Hazardous form of the Cancers found in Humans. Skin cancer is found in various types such as Melanoma, Basal and Squamous cell Carcinoma among which Melanoma is the most unpredictable. The detection of Melanoma cancer in early stage can be helpful to cure it. Computer vision can play important role in Medical Image Diagnosis and it has been proved by many existing systems. In this paper, we present a computer aided method for the detection of Melanoma Skin Cancer using Image Processing tools. The input to the system is the skin lesion image and then by applying novel image processing techniques, it analyses it to conclude about the presence of skin cancer. The Lesion Image analysis tools checks for the various Melanoma parameters Like Asymmetry, Border, Colour, Diameter,(ABCD) etc. by texture, size and shape analysis for image segmentation and feature stages. The extracted feature parameters are used to classify the image as Normal skin and Melanoma cancer lesion."
}